{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autograd.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvfVLzb46jJeFjs42Z0Ani",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monta0315/pytorch_pra/blob/main/Autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjizX4ahZBEJ"
      },
      "source": [
        "#Automatic Differential with torch.autograd\n",
        "ニューラルネットワークを訓練する際、その学習アルゴリズムとしてバックプロパゲーションが使用される\n",
        "\n",
        "バックプロパゲーションではモデルの重みなどのパラメータは損失関数に対するその変数の微分値に応じて調整されます\n",
        "\n",
        "これらの勾配の値を計算するためにPytorchにはtorch.autogradという微分エンジンが組み込まれている\n",
        "\n",
        "autogradはPytorchの計算グラフに対する勾配の自動計算を支援する\n",
        "\n",
        "シンプルな１レイヤーのネットワークを想定する\n",
        "\n",
        "入力をx、パラメータをw,b、そして適切な損失関数を決める"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-hLkA-aY_dW"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc9mgWj2Z5Xl"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(5) #inputTensor\n",
        "y = torch.zeros(3)\n",
        "w = torch.randn(5,3,requires_grad=True)\n",
        "b = torch.randn(3,requires_grad=True)\n",
        "z = torch.matmul(x,w)+b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgkx1VwCalgA"
      },
      "source": [
        "上記のコードでは以下の計算グラフを示している\n",
        "<img src=\"https://pytorch.org/tutorials/_images/comp-graph.png\" width=50% alt=\"海の写真\" title=\"空と海\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUw8lcYyas9_"
      },
      "source": [
        "上記のネットワークではw,bが最適化したいパラメータ\n",
        "\n",
        "そのため、これらの変数に対する損失関数の微分値を計算する必要性がある\n",
        "\n",
        "これらのパラメータで微分を可能にするためにreaquires_grad属性を追記する\n",
        "\n",
        "また、requires_gradはテンソルを定義する際、もしくはその後にx.requires_grad_(True)など指定もできる\n",
        "\n",
        "計算グラフを構築する際にテンソルに適用する関数は実際にはFucntionクラスのオブジェクトである\n",
        "\n",
        "これらのオブジェクトでは順伝播時に入力をどのように処理するか定義されている\n",
        "\n",
        "加えてバックプロパゲーション時に勾配をどのように計算するかも把握している\n",
        "\n",
        "そして、勾配はテンソルのgrad_fnプロパティに格納される\n",
        "\n",
        "実際にテンソルに適用する関数がバックプロパゲーション時にどのように計算するかを知っているからややこしい記述はいらないってこと？？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvICH0fEaZVb",
        "outputId": "d31c2e93-071e-46cf-d0ed-b14fe1967c54"
      },
      "source": [
        "print('Gradient function for z =',z.grad_fn)\n",
        "print('Gradient function for loss =', loss.grad_fn)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x7fc286e21fd0>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward object at 0x7fc286e21d10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kf05pm7cYz-"
      },
      "source": [
        "勾配の計算\n",
        "\n",
        "ニューラルネットワークの各パラメータを最適化するために、入力xと出力yが与えられたもとで、損失関数の各変数の偏微分値を求める必要がある\n",
        "\n",
        "$\\frac{\\partial loss}{\\partial w}$ 、$\\frac{\\partial loss}{\\partial b}$ \n",
        "\n",
        "これらの偏微分値を求めるために、loss.backward()を実行し、w.gradとb.gradの値を導出する必要がある"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wERPFSK8cFb1",
        "outputId": "74936193-6a96-4717-bf50-9ce96d02f013"
      },
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0936, 0.3226, 0.0351],\n",
            "        [0.0936, 0.3226, 0.0351],\n",
            "        [0.0936, 0.3226, 0.0351],\n",
            "        [0.0936, 0.3226, 0.0351],\n",
            "        [0.0936, 0.3226, 0.0351]])\n",
            "tensor([0.0936, 0.3226, 0.0351])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRA7EDl9dGAx"
      },
      "source": [
        "勾配計算をしない方法\n",
        "\n",
        "デフォルトでは全てのテンソルはrequires_grad = Trueであり、計算履歴が保持され、勾配計算可能な状態である\n",
        "\n",
        "しかし、勾配計算が不要なケースも存在する。\n",
        "\n",
        "例えば訓練済モデルで推論するケースなど\n",
        "\n",
        "この場合はネットワークの順伝播関数のみ使用する\n",
        "\n",
        "実装コードで勾配計算を不要にするためにはtorch.no_gradのブロックを記述する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBIXP87ec8j9",
        "outputId": "8f38510e-bf71-40f7-85e3-812ffae9d6f7"
      },
      "source": [
        "z = torch.matmul(x,w)+b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x,w)+b\n",
        "print(z.requires_grad)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S6zoijVenxQ",
        "outputId": "d83623aa-f6a6-4b0b-d152-404e1f3c9abe"
      },
      "source": [
        "z = torch.matmul(x, w)+b\n",
        "z_det = z.detach()\n",
        "print(z_det.requires_grad)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ztD-ThMeuNG"
      },
      "source": [
        "勾配を計算、追跡を不能にしたいケースは下記のような場合\n",
        "\n",
        "ネットワークの一部のパラメータを固定にしたい(frozen parameters)ケース　これはファインチューニング時にある\n",
        "\n",
        "順伝搬の計算スピードを高速化したい時"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzOt-VCPes2C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}